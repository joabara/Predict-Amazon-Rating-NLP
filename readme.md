# NLP on Amazon Laptop Reviews

## Executive Summary

* We can predict exactly how many stars a customer will rate a laptop based on their review text with an accuracy of 76%

* We can predict whether or not a product will have a positive rating (3+ stars) with an accuracy of 92%
* We can predict whether or not a product will have a negative rating (1-star) with an accuracy of 91%


## Objective
We would like to leverage Amazon customer review and rating data to understand if we can accurately predict:
* The number of stars a customer rates a laptop based on the words they use in their review.
* If a review will come in with 3+ stars based on the words used in the review.


## Data
We are going to import the Amazon laptop review data. This data was generated by taking the various Laptop brands in our initial dataset, and pulling the top 10 SKUs on Amazon and their respective reviews and ratings via a RapidAPI subscription. We chose to aggregate the laptop reviews by brand rather than product for a few reasons:

* Products can have slight differences in specs but be categorized as different products, and they can create a lot of unecessary granularity in our data

* Overall, a brand's products will all share similiar traits, and we would expect this to show in the data (i.e, Apple: expensive but beautiful; Asus: extremely reliable, high quality; etc.)



```python
import pandas as pd
import numpy as np
import scipy as scp
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

reviews = pd.read_csv('reviews.csv')
reviews = reviews.drop(columns='Unnamed: 0')
reviews.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Company</th>
      <th>Review</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Apple</td>
      <td>Thoroughly satisfied with my purchase</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Apple</td>
      <td>excelente excelente</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Apple</td>
      <td>Apple M1 chip does not support two external Mo...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Apple</td>
      <td>What did you expect? It's a Mac!</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Apple</td>
      <td>great product so far, very happy with it. Very...</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



Starting from the top, here are the highest rated brands based on average rating.


```python
top = reviews.groupby('Company').mean()
top['Number of Reviews'] = reviews.groupby('Company').sum()
top.sort_values(by='Rating', ascending=False).head(10)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rating</th>
      <th>Number of Reviews</th>
    </tr>
    <tr>
      <th>Company</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Vero</th>
      <td>4.505155</td>
      <td>437</td>
    </tr>
    <tr>
      <th>LG</th>
      <td>4.207407</td>
      <td>568</td>
    </tr>
    <tr>
      <th>MSI</th>
      <td>4.154412</td>
      <td>565</td>
    </tr>
    <tr>
      <th>Lenovo</th>
      <td>4.101010</td>
      <td>406</td>
    </tr>
    <tr>
      <th>Samsung</th>
      <td>3.981707</td>
      <td>653</td>
    </tr>
    <tr>
      <th>Fujitsu</th>
      <td>3.927928</td>
      <td>436</td>
    </tr>
    <tr>
      <th>Asus</th>
      <td>3.927007</td>
      <td>538</td>
    </tr>
    <tr>
      <th>Dell</th>
      <td>3.924528</td>
      <td>416</td>
    </tr>
    <tr>
      <th>Microsoft</th>
      <td>3.866667</td>
      <td>464</td>
    </tr>
    <tr>
      <th>Toshiba</th>
      <td>3.824742</td>
      <td>371</td>
    </tr>
  </tbody>
</table>
</div>



## Methodology

In NLP, reducing dimensionality is crucial. We will use `TfidfVectorizer` to break apart the review terms. From there, we can apply PCA to reduce dimensionality.


```python
# Import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
text = reviews['Review']

# Create a TfidfVectorizer: tfidf
tfidf = TfidfVectorizer() 

# Apply fit_transform to csr matrix
review_vector = tfidf.fit_transform(text)
review_vector.shape
```




    (2676, 8906)



Looking at the initial terms we vectorized, we are seeing a lot of individual terms which are not really relevant. In the next step we will do two things:
* Remove terms with numbers (tentative)
* We will do language checks to remove random typos (for this exercise, English, Spanish, French)


```python
words = tfidf.get_feature_names()
words[0:20]
```




    ['00',
     '000',
     '0064f45bpart',
     '01',
     '01on',
     '04',
     '06',
     '07',
     '08',
     '10',
     '100',
     '1000',
     '1000gb',
     '100c',
     '100fps',
     '100s',
     '100w',
     '100whr',
     '10300hgpu',
     '1035g1']




```python
rev_array = review_vector.toarray()
words_df = pd.DataFrame(rev_array, columns = words)
words_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>00</th>
      <th>000</th>
      <th>0064f45bpart</th>
      <th>01</th>
      <th>01on</th>
      <th>04</th>
      <th>06</th>
      <th>07</th>
      <th>08</th>
      <th>10</th>
      <th>...</th>
      <th>zoom</th>
      <th>zoomed</th>
      <th>zooming</th>
      <th>zooms</th>
      <th>zsh</th>
      <th>ágil</th>
      <th>última</th>
      <th>último</th>
      <th>único</th>
      <th>útil</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 8906 columns</p>
</div>



There are two important filters we need to use when parsing through the unique words in these reviews:
* We should remove strings with numbers since they seem to be irrelevant outside a specific context. We also notice a large boost in model score when we add this filter.
* To remove typo's, we will leverage the `enchant` library to check that these terms are in the dictionary. This will help us remove words that might not be helpful.

We noticed that some words being filtered out had a negative impact on model score, so we only check a few different languages. This can be improved upon in future versions.

Note: We can implement an autocorrect feature to send typo's to their intended term.


```python
import enchant
eng = enchant.Dict("en")
span = enchant.Dict('es')
fre = enchant.Dict('fr')
de = enchant.Dict('de')
it = enchant.Dict('it')
drops = []
for column in words_df.columns:
    english = eng.check(column)
    spanish = span.check(column)
    french = fre.check(column)
    german  = de.check(column)
    italian = it.check(column)
    if any(map(str.isdigit, column)): 
        drops.append(column)
    if not(english | spanish | french | german | italian):
        drops.append(column)

words_df = words_df.drop(columns = drops)
words_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>abajo</th>
      <th>abandoned</th>
      <th>ability</th>
      <th>able</th>
      <th>abnormalities</th>
      <th>abolladuras</th>
      <th>about</th>
      <th>above</th>
      <th>absent</th>
      <th>absolute</th>
      <th>...</th>
      <th>zona</th>
      <th>zoom</th>
      <th>zoomed</th>
      <th>zooming</th>
      <th>zooms</th>
      <th>ágil</th>
      <th>última</th>
      <th>último</th>
      <th>único</th>
      <th>útil</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6985 columns</p>
</div>



Through this filtering we've removed almost 2K words. This will help reduce dimensionality when we create models to predict rating score.


```python
review_vector = scp.sparse.csr_matrix(words_df.values)
review_vector.shape
```




    (2676, 6985)




```python
from sklearn.decomposition import TruncatedSVD
import matplotlib.pyplot as plt
svd = TruncatedSVD(n_components=1000)
svd.fit(review_vector)
features = range(svd.n_components) 
fig, ax = plt.subplots(figsize=(14,6))
ax.set_title("Fraction of Explained Variance")
ax.set_xlabel("Dimension #")
ax.set_ylabel("Explained Variance Ratio")
plt.plot(features, svd.explained_variance_ratio_)
ax
```




    
![png](output_14_1.png)
    


We have 6985 distinct terms in our review data. By using TruncatedSVD, we can reduce dimensionality down to 777 components to explain ~85% in variance.


```python
n_comps = 0
ev = 0
for comp in svd.explained_variance_ratio_:
    if ev + comp <= 0.85:
        n_comps = n_comps + 1
        ev = ev + comp

print("Optimal N Components: " + str(n_comps))
print("Explained Variance: " + str(ev))
```

    Optimal N Components: 777
    Explained Variance: 0.8499879409279631



```python
svd2 = TruncatedSVD(n_components = n_comps)
t = svd2.fit_transform(review_vector)
t = pd.DataFrame(t)
t.shape
```




    (2676, 777)



We can fit that data back to a data frame and list the columns accordingly.


```python
for column in t:
        col = t[column]
        col_name = t[column].name
        new_name = "Component_" + str(col_name)
        t = t.rename(columns={col_name: new_name})
t['Rating'] = reviews['Rating']
t.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Component_0</th>
      <th>Component_1</th>
      <th>Component_2</th>
      <th>Component_3</th>
      <th>Component_4</th>
      <th>Component_5</th>
      <th>Component_6</th>
      <th>Component_7</th>
      <th>Component_8</th>
      <th>Component_9</th>
      <th>...</th>
      <th>Component_768</th>
      <th>Component_769</th>
      <th>Component_770</th>
      <th>Component_771</th>
      <th>Component_772</th>
      <th>Component_773</th>
      <th>Component_774</th>
      <th>Component_775</th>
      <th>Component_776</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.070551</td>
      <td>0.014636</td>
      <td>-0.025105</td>
      <td>-0.012334</td>
      <td>-0.021312</td>
      <td>0.028501</td>
      <td>0.062881</td>
      <td>0.011523</td>
      <td>-0.030252</td>
      <td>0.009522</td>
      <td>...</td>
      <td>0.007673</td>
      <td>0.003688</td>
      <td>-0.001669</td>
      <td>0.003590</td>
      <td>-0.008555</td>
      <td>-0.002394</td>
      <td>-0.002800</td>
      <td>-0.006844</td>
      <td>0.003533</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.001132</td>
      <td>0.004762</td>
      <td>-0.004698</td>
      <td>0.004216</td>
      <td>0.063408</td>
      <td>-0.018864</td>
      <td>0.087361</td>
      <td>0.270264</td>
      <td>0.293683</td>
      <td>0.057021</td>
      <td>...</td>
      <td>0.001103</td>
      <td>0.000194</td>
      <td>0.003035</td>
      <td>0.001823</td>
      <td>0.001609</td>
      <td>0.005012</td>
      <td>-0.002357</td>
      <td>-0.004490</td>
      <td>-0.004206</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.195150</td>
      <td>-0.048485</td>
      <td>-0.007503</td>
      <td>-0.040549</td>
      <td>-0.041354</td>
      <td>-0.011876</td>
      <td>-0.015744</td>
      <td>0.036774</td>
      <td>-0.035365</td>
      <td>-0.013638</td>
      <td>...</td>
      <td>-0.009942</td>
      <td>-0.004321</td>
      <td>0.007673</td>
      <td>-0.009103</td>
      <td>-0.016213</td>
      <td>-0.001193</td>
      <td>0.005756</td>
      <td>0.008287</td>
      <td>-0.001654</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.120096</td>
      <td>-0.021025</td>
      <td>0.066543</td>
      <td>0.035591</td>
      <td>-0.097347</td>
      <td>-0.071523</td>
      <td>0.055934</td>
      <td>-0.006864</td>
      <td>0.006414</td>
      <td>-0.126204</td>
      <td>...</td>
      <td>-0.002180</td>
      <td>-0.003568</td>
      <td>0.012005</td>
      <td>-0.000123</td>
      <td>0.005475</td>
      <td>-0.000459</td>
      <td>-0.003666</td>
      <td>0.002353</td>
      <td>-0.001837</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.264674</td>
      <td>0.334021</td>
      <td>0.002000</td>
      <td>0.000466</td>
      <td>-0.088095</td>
      <td>0.064278</td>
      <td>-0.079453</td>
      <td>0.283830</td>
      <td>-0.271988</td>
      <td>-0.124903</td>
      <td>...</td>
      <td>-0.006299</td>
      <td>0.006519</td>
      <td>-0.000426</td>
      <td>0.002696</td>
      <td>-0.011698</td>
      <td>0.002572</td>
      <td>0.010923</td>
      <td>-0.007828</td>
      <td>0.000308</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 778 columns</p>
</div>




```python
words_df['Rating'] = reviews['Rating']
words_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>abajo</th>
      <th>abandoned</th>
      <th>ability</th>
      <th>able</th>
      <th>abnormalities</th>
      <th>abolladuras</th>
      <th>about</th>
      <th>above</th>
      <th>absent</th>
      <th>absolute</th>
      <th>...</th>
      <th>zoom</th>
      <th>zoomed</th>
      <th>zooming</th>
      <th>zooms</th>
      <th>ágil</th>
      <th>última</th>
      <th>último</th>
      <th>único</th>
      <th>útil</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 6986 columns</p>
</div>



Here we are going to write functions that will help us classify how a customer might rate a laptop based on the words used in their review. Now, you might ask, "Why do you want to create a model that predicts the rating of a product after it has already launched and reviewed? Where is the value in that?"

If this model is effective, a business will be able use this model and other text data to better predict how a product might be received in the marketplace. Furthermore, if a company is designing a new product, they can predict whether or not it will be recieved well based on consumer insight data they collect pre-launch.

For example, if Asus is testing a brand new laptop for 2023, and they have collected surveys and reviews from a test audience, they can actually run those reviews through the model and predict the customer reaction to the product quantitatively.


```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

def build_models_on_train(df, model, X_train, X_test, y_train, y_test):   
    classifier = model()
    classifier.fit(X_train, y_train)
    return classifier

def select_best_model_score(df):
    # Partition data into features and labels
    feature_cols = df.columns[df.columns != 'Rating']
    X = df[feature_cols] # Features
    y = df.Rating # Label
    
    # Create train and test segments
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,random_state=0)
    
    models_to_run = [LogisticRegression, LinearSVC, MLPClassifier, 
                 DecisionTreeClassifier, RandomForestClassifier, GaussianNB,
                Perceptron, MLPClassifier, SGDClassifier]
    
    # Score tracking
    max_score = 0
    max_build = 0
    max_RMSE = 999
    
    for algo in models_to_run:
        build = build_models_on_train(df, algo, X_train, X_test, y_train, y_test)
        pred = build.predict(X_test)
        RMSE = np.sqrt(metrics.mean_squared_error(y_test, pred))

        if RMSE < max_RMSE:
            max_score = build.score(X_test, y_test)
            max_build = build
            max_RMSE = RMSE        
    predicted = max_build.predict(X_test)
    
    print()
    print("Best build model is: ")
    print(max_build)
    print("Build model score (Accuracy): " + str(max_score))
    print("MAE = {:5.4f}".format(metrics.mean_absolute_error(y_test, predicted)))
    print("MSE = {:5.4f}".format(metrics.mean_squared_error(y_test, predicted)))
    print("RMSE = {:5.4f}".format(np.sqrt(metrics.mean_squared_error(y_test, predicted))))
    print("Accuracy:",metrics.accuracy_score(y_test, predicted))
    
    output = pd.DataFrame()
    inp = pd.DataFrame()
    inp['Ratings'] = y_test
    output['Ratings'] = predicted
    sns.distplot(inp['Ratings'])
    sns.distplot(output['Ratings']).set_title(str(max_build) + " Test vs. Predicted")

    return max_build, predicted
```

We are going to build two models for 1) exact star rating and 2) if ratings are 3+ stars: 
* Mark 1 will be with all the words found in the reviews predicting on Rating (words_df)
* Mark 2 will be the truncated SVD dataset predicting on Rating (t)

### Predicting Star Ratings

#### Original Word Data
```python
mk1 = select_best_model_score(words_df)
```

    
    Best build model is: 
    LinearSVC()
    Build model score (Accuracy): 0.763681592039801
    MAE = 0.4179
    MSE = 0.9900
    RMSE = 0.9950
    Accuracy: 0.763681592039801



    
![png](output_25_1.png)
    


#### Truncated SVD
```python
mk2 = select_best_model_score(t)
```

    
    Best build model is: 
    SGDClassifier()
    Build model score (Accuracy): 0.763681592039801
    MAE = 0.4129
    MSE = 0.9801
    RMSE = 0.9900
    Accuracy: 0.763681592039801



    
![png](output_26_1.png)
    


### Predicting a Positive Rating (3+ Stars)


```python
t['Rating'] = t['Rating'].apply(lambda x: 1 if x > 2 else 0)
words_df['Rating'] = words_df['Rating'].apply(lambda x: 1 if x > 2 else 0)
```

#### Original Word Data
```python
mk3 = select_best_model_score(words_df)
```

    
    Best build model is: 
    LinearSVC()
    Build model score (Accuracy): 0.917910447761194
    MAE = 0.0821
    MSE = 0.0821
    RMSE = 0.2865
    Accuracy: 0.917910447761194



    
![png](output_29_1.png)
    

#### Truncated SVD
```python
mk4 = select_best_model_score(t)
```

    
    Best build model is: 
    Perceptron()
    Build model score (Accuracy): 0.8955223880597015
    MAE = 0.1045
    MSE = 0.1045
    RMSE = 0.3232
    Accuracy: 0.8955223880597015



    
![png](output_30_1.png)
    


### Predicting a Negative Review (1-Star)


```python
words_df['Rating'] = reviews['Rating']
t['Rating'] = reviews['Rating']
t['Rating'] = t['Rating'].apply(lambda x: 1 if x == 1 else 0)
words_df['Rating'] = words_df['Rating'].apply(lambda x: 1 if x == 1 else 0)
```

#### Original Word Data
```python
mk5 = select_best_model_score(words_df)
```

    
    Best build model is: 
    MLPClassifier()
    Build model score (Accuracy): 0.9079601990049752
    MAE = 0.0920
    MSE = 0.0920
    RMSE = 0.3034
    Accuracy: 0.9079601990049752



    
![png](output_33_1.png)
    


#### Truncated SVD
```python
mk6 = select_best_model_score(t)
```

    
    Best build model is: 
    LinearSVC()
    Build model score (Accuracy): 0.9029850746268657
    MAE = 0.0970
    MSE = 0.0970
    RMSE = 0.3115
    Accuracy: 0.9029850746268657



    
![png](output_34_1.png)
    


## Conclusion

It seems that the SGDC models running on truncated SVD data are better at predicting customer rating based on the text found in the review. One of the things it seems to do very well is rate products accurately on overall positive or negative. It classifies the majority of reviews in 1,2 star or 4,5 stars. It does have a little trouble with more nuanced reviews at 3 stars. Three stars can often mean there are some good or bad parts of a review so the model likely gets confused with those nuances.

In conclusion, we would want to export the SGDC models to help laptop / reviewing companies. Since they run on reduced dimensionality, they return better results and in a shorter timeframe as well. In the next steps below I will highlight how we can implement this model into production to drive business value.

## Next Steps & Business Implementation

There are two key improvments we will make to improve our model's effectiveness for enterprise level servicing.

Firstly, we will expand our Amazon API subscription / develop web scraping to increase a) the number of API calls for products we can look at and b) the number of reviews we can pull per product. In our implementation above, we used ~ 400 calls and we're only getting a depth of 10 reviews. We would like to remove these limits to improve review volume.

As for the implementation, there are three key steps.

First, the model must be stored and run on an Azure/AWS server. This is important because it allows for secure and scalable storage and performance for our model. We would also be able to create a load balancer for security and availability.

Secondly, we must develop an API that can 1) receive reviews data from clients, 2) store client subscription keys and 3) send back predictive outputs in a timely manner. 

Lastly, we can monetize this API by publishing it to RapidAPI and selling tiered subscriptions. This way, we can have a consistent revenue stream to upkeep to server costs. Due to customer likely to be larger firms, we can charge a premium for unlimited use at a high markup. This would allow us to have a high revenue stream and scale the server instance and model to accomodate demand.
